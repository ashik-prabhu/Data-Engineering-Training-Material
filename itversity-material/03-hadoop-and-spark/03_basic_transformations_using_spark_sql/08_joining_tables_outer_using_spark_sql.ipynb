{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Tables - Outer\n",
    "\n",
    "Let us understand how to perform outer joins using Spark SQL. There are 3 different types of outer joins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = itv002461\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "itv002461"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val username = System.getProperty(\"user.name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = itv002461\n",
       "spark = org.apache.spark.sql.SparkSession@356b7339\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@356b7339"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val username = System.getProperty(\"user.name\")\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    appName(s\"${username} | Spark SQL - Basic Transformations\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LEFT OUTER JOIN (default) - Get all the records from both the datasets which satisfies JOIN condition along with those records which are in the left side table but not in the right side table.\n",
    "* RIGHT OUTER JOIN - Get all the records from both the datasets which satisfies JOIN condition along with those records which are in the right side table but not in the left side table.\n",
    "* FULL OUTER JOIN - left union right\n",
    "* When we perform the outer join (lets say left outer join), we will see this.\n",
    "  * Get all the values from both the tables when join condition satisfies.\n",
    "  * If there are rows on left side tables for which there are no corresponding values in right side table, all the projected column values for right side table will be null.\n",
    "* Here are some of the examples for outer join.\n",
    "    * Get all the orders where there are no corresponding order items.\n",
    "    * Get all the order items where there are no corresponding orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "use itv002461_retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|   34569|201...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "+--------+--------------------+---------------+-------------------+-------------------+\n",
       "|order_id|          order_date|   order_status|order_item_order_id|order_item_subtotal|\n",
       "+--------+--------------------+---------------+-------------------+-------------------+\n",
       "|   34565|2014-02-23 00:00:...|       COMPLETE|               null|               null|\n",
       "|   34566|2014-02-23 00:00:...|PENDING_PAYMENT|              34566|             179.97|\n",
       "|   34566|2014-02-23 00:00:...|PENDING_PAYMENT|              34566|              250.0|\n",
       "|   34567|2014-02-23 00:00:...|SUSPECTED_FRAUD|               null|               null|\n",
       "|   34568|2014-02-23 00:00:...|       COMPLETE|               null|               null|\n",
       "|   34569|2014-02-23 00:00:...|       COMPLETE|               null|               null|\n",
       "|   34570|2014-02-23 00:00:...|         CLOSED|              34570|              49.98|\n",
       "|   34570|2014-02-23 00:00:...|         CLOSED|              34570|             119.97|\n",
       "|   34570|2014-02-23 00:00:...|         CLOSED|              34570|              200.0|\n",
       "|   34570|2014-02-23 00:00:...|         CLOSED|              34570|             239.96|\n",
       "+--------+--------------------+---------------+-------------------+-------------------+\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT o.order_id,\n",
    "    o.order_date,\n",
    "    o.order_status,\n",
    "    oi.order_item_order_id,\n",
    "    oi.order_item_subtotal\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|  183650|\n",
       "+--------+\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count(1)\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|      40|201...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "+--------+--------------------+---------------+-------------------+-------------------+\n",
       "|order_id|          order_date|   order_status|order_item_order_id|order_item_subtotal|\n",
       "+--------+--------------------+---------------+-------------------+-------------------+\n",
       "|       3|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
       "|       6|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
       "|      22|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
       "|      26|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
       "|      32|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
       "|      40|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
       "|      47|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
       "|      53|2013-07-25 00:00:...|     PROCESSING|               null|               null|\n",
       "|      54|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
       "|      55|2013-07-25 00:00:...|        PENDING|               null|               null|\n",
       "+--------+--------------------+---------------+-------------------+-------------------+\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT o.order_id,\n",
    "    o.order_date,\n",
    "    o.order_status,\n",
    "    oi.order_item_order_id,\n",
    "    oi.order_item_subtotal\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "WHERE oi.order_item_order_id IS NULL\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|   11452|\n",
       "+--------+\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count(1)\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "WHERE oi.order_item_order_id IS NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|    5189|\n",
       "+--------+\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count(1)\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "WHERE oi.order_item_order_id IS NULL\n",
    "    AND o.order_status IN ('COMPLETE', 'CLOSED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|   35212|2014-02-27 00:00:...|  PROC...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "+--------+--------------------+------------+-------------------+-------------------+\n",
       "|order_id|          order_date|order_status|order_item_order_id|order_item_subtotal|\n",
       "+--------+--------------------+------------+-------------------+-------------------+\n",
       "|   35210|2014-02-27 00:00:...|     ON_HOLD|              35210|             199.92|\n",
       "|   35211|2014-02-27 00:00:...|    COMPLETE|              35211|             239.96|\n",
       "|   35212|2014-02-27 00:00:...|  PROCESSING|              35212|              49.98|\n",
       "|   35212|2014-02-27 00:00:...|  PROCESSING|              35212|             299.97|\n",
       "|   35212|2014-02-27 00:00:...|  PROCESSING|              35212|              249.9|\n",
       "|   35212|2014-02-27 00:00:...|  PROCESSING|              35212|              49.98|\n",
       "|   35212|2014-02-27 00:00:...|  PROCESSING|              35212|             149.94|\n",
       "|   35213|2014-02-27 00:00:...|      CLOSED|              35213|             239.96|\n",
       "|   35213|2014-02-27 00:00:...|      CLOSED|              35213|              150.0|\n",
       "|   35213|2014-02-27 00:00:...|      CLOSED|              35213|             299.98|\n",
       "+--------+--------------------+------------+-------------------+-------------------+\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT o.order_id,\n",
    "    o.order_date,\n",
    "    o.order_status,\n",
    "    oi.order_item_order_id,\n",
    "    oi.order_item_subtotal\n",
    "FROM orders o RIGHT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|  172198|\n",
       "+--------+\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count(1)\n",
    "FROM orders o RIGHT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+----------+------------+-------------------+-------------------+\n",
       "|order_id|order_date|order_status|order_item_order_id|order_item_subtotal|\n",
       "+--------+----------+------------+-------------------+-------------------+\n",
       "+--------+----------+------------+-------------------+-------------------+\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT o.order_id,\n",
    "    o.order_date,\n",
    "    o.order_status,\n",
    "    oi.order_item_order_id,\n",
    "    oi.order_item_subtotal\n",
    "FROM orders o RIGHT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "WHERE o.order_id IS NULL\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using Spark SQL with Python or Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------+-------------------+-------------------+\n",
      "|order_id|          order_date|   order_status|order_item_order_id|order_item_subtotal|\n",
      "+--------+--------------------+---------------+-------------------+-------------------+\n",
      "|       1|2013-07-25 00:00:...|         CLOSED|                  1|             299.98|\n",
      "|       2|2013-07-25 00:00:...|PENDING_PAYMENT|                  2|             129.99|\n",
      "|       2|2013-07-25 00:00:...|PENDING_PAYMENT|                  2|              250.0|\n",
      "|       2|2013-07-25 00:00:...|PENDING_PAYMENT|                  2|             199.99|\n",
      "|       3|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
      "|       4|2013-07-25 00:00:...|         CLOSED|                  4|             199.92|\n",
      "|       4|2013-07-25 00:00:...|         CLOSED|                  4|              150.0|\n",
      "|       4|2013-07-25 00:00:...|         CLOSED|                  4|             299.95|\n",
      "|       4|2013-07-25 00:00:...|         CLOSED|                  4|              49.98|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|             129.99|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|             299.98|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|              99.96|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|             299.95|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|             299.98|\n",
      "|       6|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
      "|       7|2013-07-25 00:00:...|       COMPLETE|                  7|              79.95|\n",
      "|       7|2013-07-25 00:00:...|       COMPLETE|                  7|             299.98|\n",
      "|       7|2013-07-25 00:00:...|       COMPLETE|                  7|             199.99|\n",
      "|       8|2013-07-25 00:00:...|     PROCESSING|                  8|               50.0|\n",
      "|       8|2013-07-25 00:00:...|     PROCESSING|                  8|             199.92|\n",
      "+--------+--------------------+---------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT o.order_id,\n",
    "    o.order_date,\n",
    "    o.order_status,\n",
    "    oi.order_item_order_id,\n",
    "    oi.order_item_subtotal\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  183650|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT count(1)\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------+-------------------+-------------------+\n",
      "|order_id|          order_date|   order_status|order_item_order_id|order_item_subtotal|\n",
      "+--------+--------------------+---------------+-------------------+-------------------+\n",
      "|       3|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
      "|       6|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
      "|      22|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
      "|      26|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
      "|      32|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
      "|      40|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
      "|      47|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
      "|      53|2013-07-25 00:00:...|     PROCESSING|               null|               null|\n",
      "|      54|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
      "|      55|2013-07-25 00:00:...|        PENDING|               null|               null|\n",
      "|      60|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
      "|      76|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
      "|      78|2013-07-25 00:00:...| PAYMENT_REVIEW|               null|               null|\n",
      "|      79|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
      "|      80|2013-07-25 00:00:...|       COMPLETE|               null|               null|\n",
      "|      82|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
      "|      85|2013-07-25 00:00:...|        PENDING|               null|               null|\n",
      "|      86|2013-07-25 00:00:...|PENDING_PAYMENT|               null|               null|\n",
      "|      89|2013-07-25 00:00:...|        ON_HOLD|               null|               null|\n",
      "|      90|2013-07-25 00:00:...|         CLOSED|               null|               null|\n",
      "+--------+--------------------+---------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT o.order_id,\n",
    "    o.order_date,\n",
    "    o.order_status,\n",
    "    oi.order_item_order_id,\n",
    "    oi.order_item_subtotal\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "WHERE oi.order_item_order_id IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   11452|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT count(1)\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "WHERE oi.order_item_order_id IS NULL\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    5189|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT count(1)\n",
    "FROM orders o LEFT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "WHERE oi.order_item_order_id IS NULL\n",
    "    AND o.order_status IN ('COMPLETE', 'CLOSED')\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------+-------------------+-------------------+\n",
      "|order_id|          order_date|   order_status|order_item_order_id|order_item_subtotal|\n",
      "+--------+--------------------+---------------+-------------------+-------------------+\n",
      "|       1|2013-07-25 00:00:...|         CLOSED|                  1|             299.98|\n",
      "|       2|2013-07-25 00:00:...|PENDING_PAYMENT|                  2|             199.99|\n",
      "|       2|2013-07-25 00:00:...|PENDING_PAYMENT|                  2|              250.0|\n",
      "|       2|2013-07-25 00:00:...|PENDING_PAYMENT|                  2|             129.99|\n",
      "|       4|2013-07-25 00:00:...|         CLOSED|                  4|              49.98|\n",
      "|       4|2013-07-25 00:00:...|         CLOSED|                  4|             299.95|\n",
      "|       4|2013-07-25 00:00:...|         CLOSED|                  4|              150.0|\n",
      "|       4|2013-07-25 00:00:...|         CLOSED|                  4|             199.92|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|             299.98|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|             299.95|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|              99.96|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|             299.98|\n",
      "|       5|2013-07-25 00:00:...|       COMPLETE|                  5|             129.99|\n",
      "|       7|2013-07-25 00:00:...|       COMPLETE|                  7|             199.99|\n",
      "|       7|2013-07-25 00:00:...|       COMPLETE|                  7|             299.98|\n",
      "|       7|2013-07-25 00:00:...|       COMPLETE|                  7|              79.95|\n",
      "|       8|2013-07-25 00:00:...|     PROCESSING|                  8|             179.97|\n",
      "|       8|2013-07-25 00:00:...|     PROCESSING|                  8|             299.95|\n",
      "|       8|2013-07-25 00:00:...|     PROCESSING|                  8|             199.92|\n",
      "|       8|2013-07-25 00:00:...|     PROCESSING|                  8|               50.0|\n",
      "+--------+--------------------+---------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT o.order_id,\n",
    "    o.order_date,\n",
    "    o.order_status,\n",
    "    oi.order_item_order_id,\n",
    "    oi.order_item_subtotal\n",
    "FROM orders o RIGHT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.SparkException",
     "evalue": "Exception thrown in awaitResult: ",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkException: Exception thrown in awaitResult:",
      "  at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)",
      "  at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:146)",
      "  at org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:387)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:144)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:140)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:140)",
      "  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:117)",
      "  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenOuter(BroadcastHashJoinExec.scala:259)",
      "  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:102)",
      "  at org.apache.spark.sql.execution.CodegenSupport$class.constructDoConsumeFunction(WholeStageCodegenExec.scala:216)",
      "  at org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:187)",
      "  at org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:374)",
      "  at org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:403)",
      "  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)",
      "  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)",
      "  at org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:374)",
      "  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:96)",
      "  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)",
      "  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)",
      "  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)",
      "  at org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:47)",
      "  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)",
      "  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)",
      "  at org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:37)",
      "  at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduceWithoutKeys(HashAggregateExec.scala:238)",
      "  at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduce(HashAggregateExec.scala:164)",
      "  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)",
      "  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)",
      "  at org.apache.spark.sql.execution.aggregate.HashAggregateExec.produce(HashAggregateExec.scala:40)",
      "  at org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:544)",
      "  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:598)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)",
      "  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)",
      "  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)",
      "  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)",
      "  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)",
      "  at org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)",
      "  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:339)",
      "  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)",
      "  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)",
      "  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)",
      "  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)",
      "  at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)",
      "  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)",
      "  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3369)",
      "  at org.apache.spark.sql.Dataset.head(Dataset.scala:2550)",
      "  at org.apache.spark.sql.Dataset.take(Dataset.scala:2764)",
      "  at org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)",
      "  at org.apache.spark.sql.Dataset.showString(Dataset.scala:291)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:751)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:710)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:719)",
      "  ... 42 elided",
      "Caused by: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.",
      "This stopped SparkContext was created at:",
      "org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)",
      "<init>(<console>:37)",
      "<init>(<console>:44)",
      "<init>(<console>:46)",
      "<init>(<console>:48)",
      "<init>(<console>:50)",
      "<init>(<console>:52)",
      "<init>(<console>:54)",
      ".<init>(<console>:58)",
      ".<clinit>(<console>)",
      ".$print$lzycompute(<console>:7)",
      ".$print(<console>:6)",
      "$print(<console>)",
      "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
      "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
      "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
      "java.lang.reflect.Method.invoke(Method.java:498)",
      "scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:793)",
      "scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1054)",
      "scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:645)",
      "The currently active SparkContext was created at:",
      "(No active SparkContext.)",
      "  at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)",
      "  at org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:2359)",
      "  at org.apache.spark.SparkContext.defaultMinPartitions(SparkContext.scala:2368)",
      "  at org.apache.spark.sql.hive.HadoopTableReader.<init>(TableReader.scala:82)",
      "  at org.apache.spark.sql.hive.execution.HiveTableScanExec.org$apache$spark$sql$hive$execution$HiveTableScanExec$$hadoopReader$lzycompute(HiveTableScanExec.scala:105)",
      "  at org.apache.spark.sql.hive.execution.HiveTableScanExec.org$apache$spark$sql$hive$execution$HiveTableScanExec$$hadoopReader(HiveTableScanExec.scala:105)",
      "  at org.apache.spark.sql.hive.execution.HiveTableScanExec$$anonfun$10.apply(HiveTableScanExec.scala:188)",
      "  at org.apache.spark.sql.hive.execution.HiveTableScanExec$$anonfun$10.apply(HiveTableScanExec.scala:188)",
      "  at org.apache.spark.util.Utils$.withDummyCallSite(Utils.scala:2470)",
      "  at org.apache.spark.sql.hive.execution.HiveTableScanExec.doExecute(HiveTableScanExec.scala:187)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)",
      "  at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:123)",
      "  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeCollectIterator(SparkPlan.scala:306)",
      "  at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:79)",
      "  at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:76)",
      "  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withExecutionId$1.apply(SQLExecution.scala:103)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withExecutionId(SQLExecution.scala:100)",
      "  at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:75)",
      "  at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:75)",
      "  at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)",
      "  at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)",
      "  ... 3 more"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT count(1)\n",
    "FROM orders o RIGHT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-------------------+-------------------+\n",
      "|order_id|order_date|order_status|order_item_order_id|order_item_subtotal|\n",
      "+--------+----------+------------+-------------------+-------------------+\n",
      "+--------+----------+------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT o.order_id,\n",
    "    o.order_date,\n",
    "    o.order_status,\n",
    "    oi.order_item_order_id,\n",
    "    oi.order_item_subtotal\n",
    "FROM orders o RIGHT OUTER JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "WHERE o.order_id IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Spark 2 - Scala",
   "language": "scala",
   "name": "spark_2_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
