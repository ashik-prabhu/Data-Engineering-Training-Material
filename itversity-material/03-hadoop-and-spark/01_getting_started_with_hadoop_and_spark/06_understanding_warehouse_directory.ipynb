{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Warehouse Directory\n",
    "\n",
    "Let us go through the details related to Spark Metastore Warehouse Directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Database in Spark SQL is nothing but directory in underlying file system like HDFS. \n",
    "* A Spark Metastore Table is nothing but directory in underlying file systems like HDFS.\n",
    "* A Partition of Spark Metastore Table is nothing but directory in underlying file systems like HDFS under table.\n",
    "* Warehouse Directory is the base directory where directories related to databases, tables go by default.\n",
    "* It is controlled by `spark.sql.warehouse.dir`. You can get the value by saying `SET spark.sql.warehouse.dir;`\n",
    "> <span style=\"color:red\">Do not overwrite this property Spark SQL CLI. It will not have any effect.</span>\n",
    "* Underlying directory for a database will have **.db** extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = itv002461\n",
       "spark = org.apache.spark.sql.SparkSession@10418006\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@10418006"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val username = System.getProperty(\"user.name\")\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    master(\"yarn\").\n",
    "    appName(s\"${username} | Spark SQL - Getting Started\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "+--------------------+--------------------+\n",
       "|                 key|               value|\n",
       "+--------------------+--------------------+\n",
       "|spark.sql.warehou...|/user/itv002461/w...|\n",
       "+--------------------+--------------------+\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SET spark.sql.warehouse.dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Spark 2 - Scala",
   "language": "scala",
   "name": "spark_2_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
