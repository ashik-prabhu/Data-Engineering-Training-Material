{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managed Tables - Exercise\n",
    "\n",
    "Let us use NYSE data and see how we can create tables in Spark Metastore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = itv002461\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "itv002461"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val username = System.getProperty(\"user.name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = itv002461\n",
       "spark = org.apache.spark.sql.SparkSession@917bba7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@917bba7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val username = System.getProperty(\"user.name\")\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    appName(s\"${username} | Spark SQL - Managing Tables - Basic DDL and DML\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Duration: **30 Minutes**\n",
    "* Data Location (Local): /data/nyse_all/nyse_data\n",
    "* Create a database with the name - YOUR_OS_USER_NAME_nyse\n",
    "* Table Name: nyse_eod\n",
    "* File Format: TEXTFILE (default)\n",
    "* Review the files by running Linux commands before using data sets. Data is compressed and we can load the files as is.\n",
    "* Copy one of the zip file to your home directory and preview the data. There should be 7 fields. You need to determine the delimiter.\n",
    "* Field Names: stockticker, tradedate, openprice, highprice, lowprice, closeprice, volume. For example, you need to use `BIGINT` for volume not `INT`.\n",
    "* Determine correct data types based on the values\n",
    "* Create Managed table with default Delimiter.\n",
    "> As delimiters in data and table are not same, you need to figure out how to get data into the target table.\n",
    "* Make sure the data is copied into the table as per the structure defined and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Magic sql failed to execute with error: \n",
       "org.apache.hadoop.hive.ql.metadata.HiveException: InvalidOperationException(message:Database itv002461_nyse is not empty. One or more tables exist.);"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    " DROP DATABASE IF EXISTS itv002461_nyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE DATABASE itv002461_nyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "USE itv002461_nyse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "DROP TABLE IF EXISTS nyse_eod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "CREATE TABLE IF NOT EXISTS nyse_eod(\n",
    "    stockticker STRING,\n",
    "    tradedate INT,\n",
    "    openprice FLOAT,\n",
    "    highprice FLOAT,\n",
    "    lowprice FLOAT,\n",
    "    closeprice FLOAT,\n",
    "    volume BIGINT  \n",
    ")ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "LOAD DATA LOCAL INPATH '/home/itv002461/tables' OVERWRITE INTO TABLE nyse_eod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val username = System.getProperty(\"user.name\")\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    appName(s\"${username} | Spark SQL - Managing Tables - Basic DDL and DML\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Run the following queries to ensure that you will be able to read the data.\n",
    "\n",
    "```\n",
    "DESCRIBE FORMATTED YOUR_OS_USER_NAME_nyse.nyse_eod;\n",
    "SELECT * FROM YOUR_OS_USER_NAME_nyse.nyse_eod LIMIT 10\n",
    "SELECT count(1) FROM YOUR_OS_USER_NAME_nyse.nyse_eod;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                        |comment|\n",
      "+----------------------------+---------------------------------------------------------------------------------+-------+\n",
      "|stockticker                 |string                                                                           |null   |\n",
      "|tradedate                   |int                                                                              |null   |\n",
      "|openprice                   |float                                                                            |null   |\n",
      "|highprice                   |float                                                                            |null   |\n",
      "|lowprice                    |float                                                                            |null   |\n",
      "|closeprice                  |float                                                                            |null   |\n",
      "|volume                      |bigint                                                                           |null   |\n",
      "|                            |                                                                                 |       |\n",
      "|# Detailed Table Information|                                                                                 |       |\n",
      "|Database                    |itv002461_nyse                                                                   |       |\n",
      "|Table                       |nyse_eod                                                                         |       |\n",
      "|Owner                       |itv002461                                                                        |       |\n",
      "|Created Time                |Mon May 30 10:17:19 EDT 2022                                                     |       |\n",
      "|Last Access                 |Wed Dec 31 19:00:00 EST 1969                                                     |       |\n",
      "|Created By                  |Spark 2.4.7                                                                      |       |\n",
      "|Type                        |MANAGED                                                                          |       |\n",
      "|Provider                    |hive                                                                             |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1653920277]                                               |       |\n",
      "|Statistics                  |407672633 bytes                                                                  |       |\n",
      "|Location                    |hdfs://m01.itversity.com:9000/user/itv002461/warehouse/itv002461_nyse.db/nyse_eod|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                               |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                                         |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                       |       |\n",
      "|Storage Properties          |[field.delim=,, serialization.format=,]                                          |       |\n",
      "|Partition Provider          |Catalog                                                                          |       |\n",
      "+----------------------------+---------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// There should not be field delimiter as the requirement is to use default delimiter\n",
    "spark.sql(\"DESCRIBE FORMATTED itv002461_nyse.nyse_eod\").show(200, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|      ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "+-----------+---------+---------+---------+--------+----------+------+\n",
       "|stockticker|tradedate|openprice|highprice|lowprice|closeprice|volume|\n",
       "+-----------+---------+---------+---------+--------+----------+------+\n",
       "|          A| 20010101|    54.75|    54.75|   54.75|     54.75|     0|\n",
       "|         AA| 20010101|    100.5|    100.5|   100.5|     100.5|     0|\n",
       "|        ABB| 20010101|    20.25|    20.25|   20.25|     20.25|     0|\n",
       "|        ABC| 20010101|   12.625|   12.625|  12.625|    12.625|     0|\n",
       "|        ABM| 20010101|    15.31|    15.31|   15.31|     15.31|     0|\n",
       "|        ABT| 20010101|    48.44|    48.44|   48.44|     48.44|     0|\n",
       "|        ABX| 20010101|    16.38|    16.38|   16.38|     16.38|     0|\n",
       "|        ACP| 20010101|     8.94|     8.94|    8.94|      8.94|     0|\n",
       "|        ACV| 20010101|    28.54|    28.54|   28.54|     28.54|     0|\n",
       "|        ADC| 20010101|    13.75|    13.75|   13.75|     13.75|     0|\n",
       "+-----------+---------+---------+---------+--------+----------+------+\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM itv002461_nyse.nyse_eod LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "| 9384739|\n",
       "+--------+\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count(1) FROM itv002461_nyse.nyse_eod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2 - Scala",
   "language": "scala",
   "name": "spark_2_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
