{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Content from Website\n",
    "\n",
    "Let us read the content from the website and get the length of the content using `BeautifulSoup` and Python pure collections.\n",
    "* First, we will explore how to read the main content for single page.\n",
    "* We will then create list for all the urls from which we want to extract the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "page_url = 'https://python.itversity.com/04_postgres_database_operations/04_ddl_data_definition_language.html'\n",
    "page = requests.get(page_url)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This will read the content from the entire page. However, we are interested in the main content at the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Main content at the center is under div tag with id `main-content`. We can find for that tag and use `get_text` to extract the main content from a single page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', id='main-content').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let us get the text content for all the pages.\n",
    "  * Get all the urls that need to be scraped in a list.\n",
    "  * For each url, extract the content and add to a list along with the url.\n",
    "* We should get the content as well as url in the new list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "python_base_url = 'https://python.itversity.com'\n",
    "python_url = f'{python_base_url}/mastering-python.html'\n",
    "python_page = requests.get(python_url)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(python_page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = soup.find('nav', {'id': 'bd-docs-nav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_urls = []\n",
    "for a in nav.find_all('a', {'class': 'reference internal'}):\n",
    "    if a['href'] != '#':\n",
    "        first_level_urls.append(a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = []\n",
    "for first_level_url in first_level_urls:\n",
    "    url = f\"{python_base_url}/{first_level_url}\"\n",
    "    all_urls.append(url)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    current_nav = soup.find('nav', {'id': 'bd-docs-nav'})\n",
    "    current_href = current_nav.find('li', {'class': 'toctree-l1 current active'})\n",
    "    for second_level_href in current_href.find_all('a', {'class': 'reference internal'}):\n",
    "        all_urls.append(f\"{'/'.join(url.split('/')[:-1])}/{second_level_href['href']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "url_and_content_list = []\n",
    "for content_url in all_urls:\n",
    "    content_page = requests.get(content_url)\n",
    "    content_soup = BeautifulSoup(content_page.content, 'html.parser')\n",
    "    content_text = content_soup.find('div', id='main-content').get_text()\n",
    "    url_and_content_list.append((content_url, content_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in url_and_content_list[:10]:\n",
    "    print(f'{url[0]} : {len(url[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
