{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Loading of Data\n",
    "\n",
    "Let us understand how we should take care of loading data in batches. We will perform load using multiple approaches to understand which one is better.\n",
    "* Approach 1: Insert and commit each record. Whenever there is a commit in database, there is considerable amount of overhead.\n",
    "* Approach 2: Insert one record at a time, but commit at the end.\n",
    "* Approach 3: Insert all records at once and commit at the end.\n",
    "* Approach 4: Insert records in chunks or batches and commit per chunk or batch.\n",
    "\n",
    "We should follow the fourth approach while dealing with huge amounts of data. It will facilitate us to restartability or recoverability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 02_function_get_database_connection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cursor(connection):\n",
    "    return connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 06_reading_data_from_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_customer_id</th>\n",
       "      <th>order_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>11599</td>\n",
       "      <td>CLOSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>256</td>\n",
       "      <td>PENDING_PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>12111</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id             order_date  order_customer_id     order_status\n",
       "0         1  2013-07-25 00:00:00.0              11599           CLOSED\n",
       "1         2  2013-07-25 00:00:00.0                256  PENDING_PAYMENT\n",
       "2         3  2013-07-25 00:00:00.0              12111         COMPLETE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"\"\"INSERT INTO orders\n",
    "         (order_id, order_date, order_customer_id, order_status)\n",
    "         VALUES\n",
    "         (%s, %s, %s, %s)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Inserting and committing one row in each iteration. Commit is quite expensive as it result in database checkpoint.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders(connection, cursor, query, data):\n",
    "    for rec in data:\n",
    "        cursor.execute(query, rec)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = get_cursor(retail_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 406 ms, sys: 313 ms, total: 719 ms\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "load_orders(retail_connection, cursor, query, orders.values.tolist()[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('TRUNCATE TABLE orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Inserting one row at a time but committing at the end. Even though it is much faster than previous approach, it is transferring one record at a time between Python Engine and Database Engine.\n",
    "\n",
    "We can further tune by leveraging batch insert.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders(connection, cursor, query, data):\n",
    "    for rec in data:\n",
    "        cursor.execute(query, rec)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = get_cursor(retail_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 905 ms, sys: 468 ms, total: 1.37 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inserting all orders\n",
    "load_orders(retail_connection, cursor, query, orders.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('TRUNCATE TABLE orders')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "All the records will be inserted as part of one batch insert operation. If there is lot of data to be inserted, then this might start running into issues such as out of memory.\n",
    "\n",
    "Also, if the job fails in the middle then all the data that is transferred thus far will be lost. Hence it is better to batch with manageable size and then insert as well as commit.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders(connection, cursor, query, data):\n",
    "    cursor.executemany(query, data)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = get_cursor(retail_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 839 ms, sys: 486 ms, total: 1.33 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inserting all orders\n",
    "load_orders(retail_connection, cursor, query, orders.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "You might not see significant difference in performance as our database is running in the same server from where the code is running to insert the data.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('TRUNCATE TABLE orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68883"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orders.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10000, 20000, 30000, 40000, 50000, 60000]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0, len(orders.values.tolist()), 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders(connection, cursor, query, data, batch_size=10000):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        cursor.executemany(query, data[i:i+batch_size])\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = get_cursor(retail_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 890 ms, sys: 465 ms, total: 1.36 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inserting all orders\n",
    "load_orders(retail_connection, cursor, query, orders.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DATABASE_URL=postgresql://itversity_retail_user:retail_password@localhost:5432/itversity_retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.RuntimeException",
     "evalue": " No datasource",
     "output_type": "error",
     "text": "java.lang.RuntimeException: No datasource",
     "traceback": [
      "\u001b[1;31mjava.lang.RuntimeException: No datasource\u001b[0;0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sql started successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count(1) FROM orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
