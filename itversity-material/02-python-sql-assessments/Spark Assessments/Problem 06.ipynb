{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 06\n",
    "\n",
    "Weightage: 25\n",
    "\n",
    "Get cities with top ten female member count from each state. There is a chance that more than 1 city might get the same rank if the counts are same. You need to get all the cities which contain top ten female member count from each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "All of the address data is available under **/public/addresses**. Here is the schema.\n",
    "```\n",
    "root\n",
    " |-- address: struct (nullable = true)\n",
    " |    |-- city: string (nullable = true)\n",
    " |    |-- postal_code: string (nullable = true)\n",
    " |    |-- state: string (nullable = true)\n",
    " |    |-- street: string (nullable = true)\n",
    " |-- email: string (nullable = true)\n",
    " |-- first_name: string (nullable = true)\n",
    " |-- gender: string (nullable = true)\n",
    " |-- id: long (nullable = true)\n",
    " |-- ip_address: string (nullable = true)\n",
    " |-- last_name: string (nullable = true)\n",
    " |-- phone_numbers: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Requirements\n",
    "* Place the result in the HDFS Directory \n",
    "```\n",
    "/user/`whoami`/mock_test_02/problem06/solution\n",
    "```\n",
    "* Use CSV and save the output to exactly one file. Make sure to preserve the header.\n",
    "* Here are the column names. Data types should be same as input data.\n",
    "```\n",
    " |-- state: string\n",
    " |-- city:string\n",
    " |-- female_count: long\n",
    "```\n",
    "* Data should be sorted in ascending order by state and then in descending order by count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Here are the self validation steps:\n",
    "* Run the following to check number of files.\n",
    "```\n",
    "hdfs dfs -ls /user/`whoami`/mock_test_02/problem06/solution\n",
    "```\n",
    "* Run the following to validate the data. Review the data to see if it is sorted in ascending order by state and then in descending order by count.\n",
    "```\n",
    "hdfs dfs -cat /user/`whoami`/mock_test_02/problem06/solution/part*\n",
    "```\n",
    "* Run this command to get the count including header. Result should be 320.\n",
    "```\n",
    "hdfs dfs -cat /user/`whoami`/mock_test_02/problem06/solution/part*|wc -l\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    appName(f'Problem 06 | {username}'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df=spark.read.json('/public/addresses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,lit,count,dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "spec=Window.\\\n",
    "        partitionBy('state'). \\\n",
    "        orderBy(col('state').asc(),col('female_count').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=read_df. \\\n",
    "    filter(col('gender')=='Female'). \\\n",
    "    select(col('address').state.alias('state'),col('address').city.alias('city')). \\\n",
    "    groupBy('state','city'). \\\n",
    "    agg(count(lit(1)).alias('female_count')). \\\n",
    "    orderBy('state',col('female_count').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=df. \\\n",
    "        withColumn('dense_rank',dense_rank().over(spec)).\\\n",
    "        orderBy('state',col('female_count').desc()). \\\n",
    "        filter(col('dense_rank')<=10). \\\n",
    "        drop('dense_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output. \\\n",
    "    coalesce(1). \\\n",
    "    write. \\\n",
    "    csv(f'/user/{username}/mock_test_02/problem06/solution',\n",
    "        header=True,\n",
    "        mode='overwrite'\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 itv002461 supergroup          0 2022-06-29 05:17 /user/itv002461/mock_test_02/problem06/solution/_SUCCESS\n",
      "-rw-r--r--   3 itv002461 supergroup       7643 2022-06-29 05:17 /user/itv002461/mock_test_02/problem06/solution/part-00000-ec49dc85-dd9c-4021-8fe7-3228952d6b78-c000.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "hdfs dfs -ls /user/${USER}/mock_test_02/problem06/solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "hdfs dfs -cat /user/`whoami`/mock_test_02/problem06/solution/part*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "hdfs dfs -cat /user/`whoami`/mock_test_02/problem06/solution/part*|wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col,lit,count\n",
    "# from pyspark.sql.window import Window\n",
    "# df=read_df. \\\n",
    "#     filter(col('gender')=='Female'). \\\n",
    "#     select(col('address').state.alias('state'),col('address').city.alias('city')). \\\n",
    "#     groupBy('state','city'). \\\n",
    "#     agg(count(lit(1)).alias('female_count')). \\\n",
    "#     orderBy('state',col('female_count').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>state</th><th>city_count</th></tr>\n",
       "<tr><td>Alabama</td><td>7</td></tr>\n",
       "<tr><td>Alaska</td><td>3</td></tr>\n",
       "<tr><td>Arizona</td><td>11</td></tr>\n",
       "<tr><td>Arkansas</td><td>4</td></tr>\n",
       "<tr><td>California</td><td>65</td></tr>\n",
       "<tr><td>Colorado</td><td>11</td></tr>\n",
       "<tr><td>Connecticut</td><td>9</td></tr>\n",
       "<tr><td>Delaware</td><td>2</td></tr>\n",
       "<tr><td>District of Columbia</td><td>1</td></tr>\n",
       "<tr><td>Florida</td><td>48</td></tr>\n",
       "<tr><td>Georgia</td><td>16</td></tr>\n",
       "<tr><td>Hawaii</td><td>1</td></tr>\n",
       "<tr><td>Idaho</td><td>3</td></tr>\n",
       "<tr><td>Illinois</td><td>15</td></tr>\n",
       "<tr><td>Indiana</td><td>12</td></tr>\n",
       "<tr><td>Iowa</td><td>6</td></tr>\n",
       "<tr><td>Kansas</td><td>4</td></tr>\n",
       "<tr><td>Kentucky</td><td>5</td></tr>\n",
       "<tr><td>Louisiana</td><td>8</td></tr>\n",
       "<tr><td>Maine</td><td>1</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+----------+\n",
       "|               state|city_count|\n",
       "+--------------------+----------+\n",
       "|             Alabama|         7|\n",
       "|              Alaska|         3|\n",
       "|             Arizona|        11|\n",
       "|            Arkansas|         4|\n",
       "|          California|        65|\n",
       "|            Colorado|        11|\n",
       "|         Connecticut|         9|\n",
       "|            Delaware|         2|\n",
       "|District of Columbia|         1|\n",
       "|             Florida|        48|\n",
       "|             Georgia|        16|\n",
       "|              Hawaii|         1|\n",
       "|               Idaho|         3|\n",
       "|            Illinois|        15|\n",
       "|             Indiana|        12|\n",
       "|                Iowa|         6|\n",
       "|              Kansas|         4|\n",
       "|            Kentucky|         5|\n",
       "|           Louisiana|         8|\n",
       "|               Maine|         1|\n",
       "+--------------------+----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df. \\\n",
    "#     select('state').\\\n",
    "#     groupBy('state'). \\\n",
    "#     agg(count(lit(1)).alias('city_count')). \\\n",
    "#     orderBy('state')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
